# 快速入门

<cite>
**本文档中引用的文件**   
- [README.md](file://README.md)
- [README_CN.md](file://README_CN.md)
- [main.py](file://desktop-ui/main.py)
- [download_models.py](file://download_models.py)
- [config.py](file://manga_translator/config.py)
- [keys.py](file://manga_translator/translators/keys.py)
- [requirements_cpu.txt](file://requirements_cpu.txt)
- [requirements_gpu.txt](file://requirements_gpu.txt)
</cite>

## 目录
1. [简介](#简介)
2. [环境准备与依赖安装](#环境准备与依赖安装)
3. [模型下载与配置](#模型下载与配置)
4. [启动桌面应用程序](#启动桌面应用程序)
5. [执行首次翻译任务](#执行首次翻译任务)
6. [常见问题排查](#常见问题排查)

## 简介

本指南旨在为新手用户提供一份从零开始的完整入门教程，帮助您快速安装、配置并运行漫画图片翻译器。本项目基于 `zyddnys/manga-image-translator` 的核心引擎，并由 `hgmzhn` 开发了功能完整的桌面用户界面（UI）。通过本指南，您将学会如何根据硬件环境选择依赖、下载必要模型、启动应用，并完成一个“Hello World”式的翻译示例。

## 环境准备与依赖安装

在开始之前，请确保您的系统已安装 Python 3.8 或更高版本。推荐使用虚拟环境以避免依赖冲突。

### 1. 克隆项目仓库

首先，将项目仓库克隆到您的本地计算机：
```bash
git clone https://github.com/zyddnys/manga-image-translator.git
cd manga-image-translator
```

### 2. 创建并激活虚拟环境（可选但推荐）

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/macOS
source venv/bin/activate
```

### 3. 根据硬件选择并安装依赖

项目提供了两个不同的依赖文件，您需要根据自己的硬件（CPU或GPU）进行选择。

- **如果您使用 NVIDIA GPU 进行加速**：请安装 `requirements_gpu.txt`。
- **如果您仅使用 CPU**：请安装 `requirements_cpu.txt`。

```bash
# 安装GPU版本依赖
pip install -r requirements_gpu.txt

# 安装CPU版本依赖
pip install -r requirements_cpu.txt
```

**注意**：如果在 Windows 上安装时遇到编译错误，请先安装 Microsoft C++ Build Tools。

**Section sources**
- [requirements_cpu.txt](file://requirements_cpu.txt)
- [requirements_gpu.txt](file://requirements_gpu.txt)

## 模型下载与配置

核心翻译功能依赖于多个深度学习模型，这些模型会在首次运行时自动下载。您也可以使用提供的脚本手动触发下载。

### 使用脚本下载模型

项目根目录下的 `download_models.py` 脚本可以用于下载特定的OCR模型。

```bash
python download_models.py
```

此脚本会下载PaddleOCR的方向分类模型和v5识别模型。

### API密钥配置

对于需要API密钥的在线翻译器（如OpenAI、DeepL、Gemini等），您需要在环境变量中配置相应的密钥。

配置文件位于 `manga_translator/translators/keys.py`。您可以通过以下两种方式之一进行设置：

1.  **直接编辑 `keys.py` 文件**：找到对应的变量（如 `OPENAI_API_KEY`）并填入您的密钥。
2.  **使用环境变量**：在运行程序前，设置环境变量。例如，在命令行中：
    ```bash
    export OPENAI_API_KEY='your-api-key-here'
    python -m desktop-ui.main
    ```

支持的API密钥包括：
- `OPENAI_API_KEY`: OpenAI API密钥
- `DEEPL_AUTH_KEY`: DeepL认证密钥
- `GEMINI_API_KEY`: Google Gemini API密钥
- `BAIDU_APP_ID` 和 `BAIDU_SECRET_KEY`: 百度翻译应用ID和密钥

**Section sources**
- [download_models.py](file://download_models.py#L1-L8)
- [keys.py](file://manga_translator/translators/keys.py#L1-L50)

## 启动桌面应用程序

项目的桌面UI入口点是 `desktop-ui/main.py`。要启动应用程序，请在项目根目录下运行以下命令：

```bash
python -m desktop-ui.main
```

该命令会启动主UI进程，加载应用界面。程序使用了延迟导入技术以加快启动速度。

**Section sources**
- [main.py](file://desktop-ui/main.py#L1-L99)

## 执行首次翻译任务

现在，让我们通过一个具体的示例来完成整个翻译流程。

### 1. 添加任务
1.  启动应用程序后，点击界面中的“添加文件”或“添加文件夹”按钮。
2.  选择一张您想要翻译的测试图片（例如，一张日语漫画截图）。

### 2. 选择基础配置
在UI的设置面板中，您可以根据推荐配置进行选择：
- **翻译器 (Translator)**: 选择 `sakura` 或 `chatgpt`。
- **目标语言 (Target Language)**: 选择 `CHS` (简体中文)。
- **OCR模型 (OCR Model)**: 选择 `48px`。
- **检测器 (Detector)**: 选择 `default`。
- **修复器 (Inpainter)**: 选择 `lama_large`。

### 3. 启动翻译流水线
1.  确认输出目录。
2.  点击“开始翻译”按钮。
3.  应用程序将自动执行以下流水线：
    - **文本检测**: 识别图片中的所有文本区域。
    - **OCR识别**: 提取每个区域的原文。
    - **文本翻译**: 使用选定的翻译器将原文翻译为目标语言。
    - **图像修复**: 擦除原文所在的区域。
    - **文本渲染**: 将翻译后的文本嵌入到修复后的区域。

### 4. 查看结果
翻译完成后，结果图片将保存在指定的输出目录中，文件名与原图相同，但位于 `-translated` 后缀的文件夹内。您可以打开图片查看翻译效果。

## 常见问题排查

在初次使用时，可能会遇到一些常见问题。以下是快速排查方法：

### 模型缺失
- **现象**: 程序报错找不到模型文件。
- **解决方法**: 确保网络连接正常，模型会在首次使用时自动下载到 `./models` 目录。如果下载失败，可尝试手动运行 `download_models.py` 或检查网络代理设置。

### 依赖冲突
- **现象**: `pip install` 时出现版本冲突或编译错误。
- **解决方法**: 强烈建议使用虚拟环境。如果问题依旧，尝试更新 `pip` 并强制重新安装：
    ```bash
    pip install --upgrade --force-reinstall pip
    pip install -r requirements_cpu.txt --force-reinstall
    ```

### GPU无法使用
- **现象**: 程序无法利用GPU，运行缓慢。
- **解决方法**: 
    1.  确认已安装支持CUDA的NVIDIA显卡驱动。
    2.  确认已安装与PyTorch兼容的CUDA版本。
    3.  确保安装的是 `requirements_gpu.txt` 而非 `requirements_cpu.txt`。
    4.  在命令行中添加 `--use-gpu` 参数。

### API密钥无效
- **现象**: 使用OpenAI等服务时返回401错误。
- **解决方法**: 检查 `keys.py` 文件或环境变量中配置的API密钥是否正确无误。